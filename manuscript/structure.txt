Likeable vs edgy: Character personality and audience preferences across genres
characters have personality and we bond deeply with them [7,8,16]
examples of Elizabeth Bennet but also Homer Simpson [7,11,16]
why do we like these characters (and thus enjoy their stories?) [8,6,10]
much of our movie and book enjoyment is facilitated with empathy [8,6,10]
characters must be "3D", believable, or relatable --> allows us to empathize [12,8,10]
here we will focus on an additional trait that determines to which degree we like and thus empathize with others: their agreeablness [4,1,3,2]
psych references on agreeablenss being a crucial trait for social bonding (e.g., warmth dimension in person perception) [4,2,20]
literary findings: people complain about non-likeable characters [12,9,10]
Subheading: Can characters be TOO nice?
extreme niceness is inauthentic and doesn't feel real --> prohibits empathy [12,9]
refs about writing advice (flawed characters) [12,9]
transition to genre-specific tendencies [7,8]
refs for character differences across genres (maybe someone found that avantgarde films have more complex characters; action/kids movies have very clear villains; lovable protagonist in romance movies) [7,8,6,14]
Likeability hypothesis:
Movies with more agreeable protagonists receive higher ratings on IMDB. [1,4,16]
Genre hypothesis:
The affect of protagonist likeability on movie ratings will differ significantly across genres. [7,8,6]
Exploration of character ambiguity:
We will explore whether the dispersion of likeability annotation (i.e., protagonists who show friendly and unfriendly behaviors) predicts movie ratings and whether this effect differs across genres. [6,5]
Method
Data
Describe data from here
https://www.kaggle.com/datasets/gufukuro/movie-scripts-corpus [1,16]
Procedure
Use LLM annotation via this package
https://github.com/hannesrosenbusch/LLM_annotate/tree/main/data [2,3,5,16]
(LLM goes through movie script and observes + annotates character behaviors and statements; scores get summed over script for a character's total score)
annotate 2 characters who appear most frequently according to character meta data in kaggle dataset (must have at least 10 behaviors)
Genre is not included in metadata and will therefore be classified with perplexity (using title, release year, and director for disambiguation).
The AI agent will assign one or more genre label to each movie by picking from the 12 most common genres on IMDB according to https://medium.com/@avi22nayak/imdb-movie-analysis-f3e9e113df49
where the 12 most common genres are:
Drama, Comedy, Thriller, Action, Romance, Adventure, Crime, Sci-fi, Fantasy, Horror, Family, and Mystery
Statistical analysis
brms in R
default package setting as long as convergence is achieved
priors for coefficients are beta(1,1 )
effect of protagonist agreeability on IMDB rating (included in kaggle data). positive effect with bayes factor >10 will be interpreted as support for H1 [6,1,4]
in second step, interaction term with genre will be added [7,8,6]
if the model fits the data better than a model with only the main effects of likeability and genre, we will interpret this as evidence in favor of H2